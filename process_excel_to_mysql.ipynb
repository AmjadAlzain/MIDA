{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel to MySQL Data Pipeline\n",
    "\n",
    "This notebook processes the `EXEMPTION MIDA FOR 755 NEW.xlsx` file, translating Malay column headers to English, cleaning data, and importing it into a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql\n",
    "from mysql.connector import Error\n",
    "import re\n",
    "import numpy as np\n",
    "# --- CONFIGURATION ---\n",
    "EXCEL_PATH = 'EXEMPTION MIDA FOR 755 NEW.xlsx'\n",
    "\n",
    "# MySQL Configuration\n",
    "# Please update these credentials as needed\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',  # Enter your password here\n",
    "    'database': 'mida_exemption_db'  # The database to create/use\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRANSLATION LOGIC ---\n",
    "\n",
    "# Mapping of full Malay phrases (normalized) to English column names\n",
    "HEADER_MAPPING = {\n",
    "    'TARIKH IMPORT': 'import_date',\n",
    "    'NO DAFTAR BORANG IKRAR': 'declaration_form_registration_no',\n",
    "    'BAKI DI BAWA KEHADAPAN': 'balance_brought_forward',\n",
    "    'KUANTITI KGS': 'quantity_kgs',\n",
    "    'KUANTITI PCS': 'quantity_pcs',\n",
    "    'BAKI (KGS)': 'balance_kgs',\n",
    "    'BAKI (PCS)': 'balance_pcs',\n",
    "    'T/TANGAN PIK': 'pik_signature',\n",
    "    'T/TANGAN PNK': 'pnk_signature'\n",
    "}\n",
    "\n",
    "def clean_header(h1, h2):\n",
    "    \"\"\"\n",
    "    Combines two header rows and normalizes whitespace.\n",
    "    \"\"\"\n",
    "    combined = f\"{str(h1).strip()} {str(h2).strip()}\"\n",
    "    # Collapse multiple spaces into one\n",
    "    normalized = \" \".join(combined.split())\n",
    "    return normalized\n",
    "\n",
    "def translate_header(normalized_header):\n",
    "    \"\"\"\n",
    "    Translates the normalized header using the mapping.\n",
    "    Falls back to a snake_case conversion if not found.\n",
    "    \"\"\"\n",
    "    if normalized_header in HEADER_MAPPING:\n",
    "        return HEADER_MAPPING[normalized_header]\n",
    "    \n",
    "    # Fallback\n",
    "    print(f\"Warning: No direct translation for '{normalized_header}'. Using snake_case.\")\n",
    "    return normalized_header.lower().replace(' ', '_').replace('.', '').replace('/', '_').replace('(', '').replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Excel file...\n",
      "Warning: No direct translation for 'KUANTITI pcs'. Using snake_case.\n",
      "Warning: No direct translation for 'BAKI (pcs)'. Using snake_case.\n",
      "Warning: No direct translation for 'nan TARIKH'. Using snake_case.\n",
      "Warning: No direct translation for 'nan NO DAFTAR'. Using snake_case.\n",
      "Warning: No direct translation for 'nan BAKI DI BAWA'. Using snake_case.\n",
      "Warning: No direct translation for 'nan KUANTITI'. Using snake_case.\n",
      "Warning: No direct translation for 'nan BAKI'. Using snake_case.\n",
      "Warning: No direct translation for 'nan T/TANGAN'. Using snake_case.\n",
      "Warning: No direct translation for 'nan T/TANGAN'. Using snake_case.\n",
      "Warning: No direct translation for 'KUANTITI UNT'. Using snake_case.\n",
      "Warning: No direct translation for 'BAKI UNT'. Using snake_case.\n",
      "Successfully processed 56 sheets.\n"
     ]
    }
   ],
   "source": [
    "# --- PROCESS EXCEL FILE ---\n",
    "\n",
    "print(\"Loading Excel file...\")\n",
    "excel_file = pd.ExcelFile(EXCEL_PATH)\n",
    "\n",
    "processed_dfs = {}\n",
    "\n",
    "for sheet in excel_file.sheet_names:\n",
    "    try:\n",
    "        # 1. Read Headers (Rows 13 & 14 are indices 12 & 13)\n",
    "        # We read enough rows to cover them\n",
    "        header_df = pd.read_excel(excel_file, sheet_name=sheet, header=None, nrows=14)\n",
    "        h1_row = header_df.iloc[12]\n",
    "        h2_row = header_df.iloc[13]\n",
    "        \n",
    "        # 2. Construct Translated Column Names\n",
    "        new_columns = []\n",
    "        for h1, h2 in zip(h1_row, h2_row):\n",
    "            norm = clean_header(h1, h2)\n",
    "            trans = translate_header(norm)\n",
    "            new_columns.append(trans)\n",
    "            \n",
    "        # 3. Read Data (Skip first 14 rows)\n",
    "        df = pd.read_excel(excel_file, sheet_name=sheet, header=None, skiprows=14)\n",
    "        \n",
    "        # Assign columns\n",
    "        # Ensure column count matches. If mismatch, trim or pad.\n",
    "        if len(df.columns) == len(new_columns):\n",
    "            df.columns = new_columns\n",
    "        else:\n",
    "            print(f\"Warning: Column count mismatch in sheet '{sheet}'. Expected {len(new_columns)}, got {len(df.columns)}.\")\n",
    "            # Simple fix: truncate or take min\n",
    "            min_len = min(len(df.columns), len(new_columns))\n",
    "            df = df.iloc[:, :min_len]\n",
    "            df.columns = new_columns[:min_len]\n",
    "        \n",
    "        # 4. Generate Clean Table Name\n",
    "        # Replace non-alphanumeric with underscore, lower case\n",
    "        table_name = re.sub(r'[^a-zA-Z0-9]', '_', sheet).lower()\n",
    "        # Remove duplicate underscores\n",
    "        table_name = re.sub(r'_+', '_', table_name).strip('_')\n",
    "        \n",
    "        processed_dfs[table_name] = df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sheet '{sheet}': {e}\")\n",
    "\n",
    "print(f\"Successfully processed {len(processed_dfs)} sheets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TABLE: ball_62 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 7 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   import_date                       1 non-null      object \n",
      " 1   declaration_form_registration_no  1 non-null      object \n",
      " 2   balance_brought_forward           1 non-null      float64\n",
      " 3   quantity_kgs                      1 non-null      float64\n",
      " 4   balance_kgs                       1 non-null      float64\n",
      " 5   pik_signature                     1 non-null      object \n",
      " 6   pnk_signature                     0 non-null      float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "  import_date declaration_form_registration_no  balance_brought_forward  \\\n",
      "0  27.01.2025                     B18101053316                 252000.0   \n",
      "1         NaN                              NaN                      NaN   \n",
      "2         NaN                              NaN                      NaN   \n",
      "3         NaN                              NaN                      NaN   \n",
      "4         NaN                              NaN                      NaN   \n",
      "\n",
      "   quantity_kgs  balance_kgs pik_signature  pnk_signature  \n",
      "0        9600.0     242400.0           NaN            NaN  \n",
      "1           NaN          NaN           NaN            NaN  \n",
      "2           NaN          NaN           NaN            NaN  \n",
      "3           NaN          NaN           NaN            NaN  \n",
      "4           NaN          NaN           NaN            NaN  \n",
      "\n",
      "=== TABLE: bolt_flg_1 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   import_date                       3 non-null      object \n",
      " 1   declaration_form_registration_no  3 non-null      object \n",
      " 2   balance_brought_forward           3 non-null      float64\n",
      " 3   quantity_kgs                      3 non-null      float64\n",
      " 4   balance_kgs                       3 non-null      float64\n",
      " 5   pik_signature                     0 non-null      float64\n",
      " 6   pnk_signature                     0 non-null      float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 300.0+ bytes\n",
      "None\n",
      "  import_date declaration_form_registration_no  balance_brought_forward  \\\n",
      "0  20.09.2024                     B18109037033                   1484.4   \n",
      "1  16.10.2024                     B18110033209                    976.4   \n",
      "2  27.01.2025                     B18101053316                    976.4   \n",
      "\n",
      "   quantity_kgs  balance_kgs  pik_signature  pnk_signature  \n",
      "0         507.6        976.4            NaN            NaN  \n",
      "1         493.5        976.4            NaN            NaN  \n",
      "2         676.8        299.6            NaN            NaN  \n",
      "\n",
      "=== TABLE: sw_handle_1_side_stand_56 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 7 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   import_date                       125 non-null    object \n",
      " 1   declaration_form_registration_no  125 non-null    object \n",
      " 2   balance_brought_forward           125 non-null    float64\n",
      " 3   quantity_kgs                      125 non-null    float64\n",
      " 4   balance_kgs                       125 non-null    float64\n",
      " 5   pik_signature                     0 non-null      float64\n",
      " 6   pnk_signature                     0 non-null      float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 7.0+ KB\n",
      "None\n",
      "           import_date declaration_form_registration_no  \\\n",
      "0  2024-07-31 00:00:00                     B18107063117   \n",
      "1  2024-07-27 00:00:00                     B18107056755   \n",
      "2  2024-08-13 00:00:00                     B18108038006   \n",
      "3  2024-08-13 00:00:00                     B18108026862   \n",
      "4           13.08.2024                     B18108026846   \n",
      "\n",
      "   balance_brought_forward  quantity_kgs  balance_kgs  pik_signature  \\\n",
      "0                  21828.0          46.6      21781.4            NaN   \n",
      "1                  21781.4          46.6      21734.8            NaN   \n",
      "2                  21734.8          93.2      21641.6            NaN   \n",
      "3                  21641.6          23.3      21618.3            NaN   \n",
      "4                  21618.3          69.9      21548.4            NaN   \n",
      "\n",
      "   pnk_signature  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n"
     ]
    }
   ],
   "source": [
    "# --- INSPECT GENERATED DATAFRAMES ---\n",
    "# Displaying first few rows and datatypes of the first 3 processed tables\n",
    "\n",
    "for table_name, df in list(processed_dfs.items())[:3]:\n",
    "    print(f\"\\n=== TABLE: {table_name} ===\")\n",
    "    print(df.info())\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MySQL...\n",
      "\n",
      "MySQL Error: 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)\n"
     ]
    }
   ],
   "source": [
    "# --- DATABASE IMPORT ---\n",
    "\n",
    "def get_mysql_type(dtype):\n",
    "    \"\"\"Infer MySQL type from Pandas dtype\"\"\"\n",
    "    dtype_str = str(dtype)\n",
    "    if 'int' in dtype_str:\n",
    "        return 'INT'\n",
    "    elif 'float' in dtype_str:\n",
    "        return 'DOUBLE'\n",
    "    elif 'datetime' in dtype_str:\n",
    "        return 'DATETIME'\n",
    "    else:\n",
    "        return 'VARCHAR(255)'\n",
    "\n",
    "try:\n",
    "    # 1. Connect to MySQL Server\n",
    "    print(\"Connecting to MySQL...\")\n",
    "    conn = mysql.connector.connect(\n",
    "        host=DB_CONFIG['host'],\n",
    "        user=DB_CONFIG['user'],\n",
    "        password=DB_CONFIG['password']\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # 2. Create Database\n",
    "    db_name = DB_CONFIG['database']\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS `{db_name}`\")\n",
    "    print(f\"Database '{db_name}' ready.\")\n",
    "    \n",
    "    # 3. Switch to Database\n",
    "    conn.database = db_name\n",
    "    \n",
    "    # 4. Create Tables and Insert Data\n",
    "    for table_name, df in processed_dfs.items():\n",
    "        print(f\"Importing table '{table_name}'...\")\n",
    "        \n",
    "        # Generate CREATE TABLE SQL\n",
    "        cols_def = []\n",
    "        for col in df.columns:\n",
    "            mysql_type = get_mysql_type(df[col].dtype)\n",
    "            # Handle reserved words or special chars in columns by quoting\n",
    "            cols_def.append(f\"`{col}` {mysql_type}\")\n",
    "            \n",
    "        create_sql = f\"CREATE TABLE IF NOT EXISTS `{table_name}` ({', '.join(cols_def)})\"\n",
    "        cursor.execute(create_sql)\n",
    "        \n",
    "        # Clean Data for Insertion\n",
    "        # Convert NaN to None (NULL in SQL)\n",
    "        df_sql = df.where(pd.notnull(df), None)\n",
    "        \n",
    "        # Generate INSERT SQL\n",
    "        placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "        columns_list = ', '.join([f\"`{c}`\" for c in df.columns])\n",
    "        insert_sql = f\"INSERT INTO `{table_name}` ({columns_list}) VALUES ({placeholders})\"\n",
    "        \n",
    "        # Execute Batch Insert\n",
    "        values = [tuple(x) for x in df_sql.to_numpy()]\n",
    "        cursor.executemany(insert_sql, values)\n",
    "        \n",
    "    conn.commit()\n",
    "    print(\"\\nSUCCESS: All data imported into database.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"\\nMySQL Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'conn' in locals() and conn.is_connected():\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"MySQL connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
